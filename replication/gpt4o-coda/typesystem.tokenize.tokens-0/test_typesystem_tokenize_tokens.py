# Automatically generated by Pynguin.
import typesystem.tokenize.tokens as module_0

def test_case_0():
    float_0 = 2118.28
    int_0 = 710
    scalar_token_0 = module_0.ScalarToken(float_0, int_0, int_0)

def test_case_1():
    str_0 = '\n    Raised by `typesystem.tokenize_json()` and `typesystem.tokenize_yaml()`.\n    '
    dict_0 = {str_0: str_0, str_0: str_0, str_0: str_0, str_0: str_0, str_0: str_0, str_0: str_0}
    int_0 = -4031
    token_0 = module_0.Token(dict_0, int_0, int_0)
    bool_0 = token_0.__eq__(dict_0)
    token_1 = module_0.Token(dict_0, int_0, int_0)
    str_1 = token_1.__repr__()

def test_case_2():
    list_0 = []
    list_1 = []
    token_0 = None
    bytes_0 = b"\x9b\x16\xe1\x02_'\xc7\x9a\xec"
    dict_0 = {bytes_0: bytes_0, bytes_0: bytes_0, token_0: token_0, token_0: bytes_0}
    dict_1 = {token_0: token_0, token_0: dict_0, bytes_0: bytes_0, bytes_0: token_0}
    list_2 = [dict_1, bytes_0, dict_0]
    list_3 = [list_2]
    int_0 = 4
    int_1 = -2222
    str_0 = '.V'
    token_1 = module_0.Token(list_3, int_0, int_1, str_0)
    token_2 = token_1.lookup(list_1)
    bool_0 = token_2.__eq__(list_0)

def test_case_3():
    dict_0 = None
    int_0 = None
    int_1 = -2959
    scalar_token_0 = module_0.ScalarToken(dict_0, int_0, int_1)
    set_0 = None
    scalar_token_1 = module_0.ScalarToken(set_0, int_1, int_1)
    int_2 = 0
    int_3 = -4306
    token_0 = module_0.Token(set_0, int_3, int_0)
    int_4 = 4
    float_0 = -1843.2409
    tuple_0 = (int_4, float_0)
    token_1 = module_0.Token(tuple_0, int_4, int_4)
    token_2 = module_0.Token(scalar_token_0, int_1, int_2)

def test_case_4():
    dict_0 = {}
    list_0 = [dict_0, dict_0, dict_0, dict_0]
    dict_token_0 = module_0.DictToken(*list_0)