

# Generated at 2024-06-01 15:58:32.946401
```python
    start = NFAState()
    finish = NFAState()
    start.addarc(finish, 'a')
    
    pg = ParserGenerator()
    dfa = pg.make_dfa(start, finish)
    
    assert len(dfa) == 2
    assert dfa[0].isfinal == False
    assert dfa[1].isfinal == True
    assert len(dfa[0].arcs) == 1
    assert 'a' in dfa[0].arcs
    assert dfa[0].arcs['a'] == dfa[1]
```

# Generated at 2024-06-01 15:58:36.949628
```python
    from io import StringIO
    import sys

    class MockNFAState:
        def __init__(self):
            self.arcs = []

        def addarc(self, next, label=None):
            self.arcs.append((label, next))

    def test_ParserGenerator_dump_nfa():
        # Create a mock NFA
        start = MockNFAState()
        middle = MockNFAState()
        finish = MockNFAState()
        start.addarc(middle, 'a')
        middle.addarc(finish, 'b')

        # Capture the output of dump_nfa
        output = StringIO()
        sys.stdout = output

        # Create an instance of ParserGenerator and call dump_nfa
        pg = ParserGenerator()
        pg.dump_nfa("test", start, finish)

        # Restore stdout
        sys.stdout = sys.__stdout__

        # Check the output
        expected_output = (
            "Dump of N

# Generated at 2024-06-01 15:58:41.630693
```python
    import tokenize
    from io import StringIO

    # Mock generator to simulate token stream
    def mock_generator():
        tokens = [
            (tokenize.NAME, 'def', (1, 0), (1, 3), 'def foo():\n'),
            (tokenize.OP, '(', (1, 3), (1, 4), 'def foo():\n'),
            (tokenize.OP, ')', (1, 4), (1, 5), 'def foo():\n'),
            (tokenize.OP, ':', (1, 5), (1, 6), 'def foo():\n'),
            (tokenize.NEWLINE, '\n', (1, 6), (1, 7), 'def foo():\n'),
            (tokenize.INDENT, '    ', (2, 0), (2, 4), '    pass\n'),
            (

# Generated at 2024-06-01 15:58:44.777410
```python
    generator = tokenize.generate_tokens(io.StringIO("a : b | c").readline)
    pg = ParserGenerator(generator, "testfile")
    pg.gettoken()  # Initialize the first token
    start, end = pg.parse_rhs()
    assert isinstance(start, NFAState)
    assert isinstance(end, NFAState)
    assert len(start.arcs) == 2  # Two alternatives: 'b' and 'c'
    assert all(isinstance(arc[1], NFAState) for arc in start.arcs)
    assert all(isinstance(arc[1], NFAState) for arc in end.arcs)
```

# Generated at 2024-06-01 15:58:46.203360
```python
    pg = ParserGenerator()
    with pytest.raises(SyntaxError) as excinfo:
        pg.raise_error("Test error message %s", "with argument")
    assert str(excinfo.value) == "Test error message with argument"
```

# Generated at 2024-06-01 15:58:49.451030
```python
    pg = ParserGenerator()
    pg.dfas = {
        'S': [DFAState({NFAState(): 1}, NFAState())],
        'A': [DFAState({NFAState(): 1}, NFAState())]
    }
    pg.first = {}
    pg.calcfirst = lambda name: pg.first.update({name: {name: 1}})
    
    pg.addfirstsets()
    
    assert 'S' in pg.first
    assert 'A' in pg.first
    assert pg.first['S'] == {'S': 1}
    assert pg.first['A'] == {'A': 1}
```

# Generated at 2024-06-01 15:58:53.523719
```python
    from io import StringIO
    import tokenize

    class MockToken:
        NAME = 1
        STRING = 2
        OP = 3
        NEWLINE = 4
        ENDMARKER = 5

    class MockNFAState:
        def __init__(self):
            self.arcs = []

        def addarc(self, next, label=None):
            self.arcs.append((label, next))

    class MockDFAState:
        def __init__(self, nfaset, finish):
            self.nfaset = nfaset
            self.isfinal = finish in nfaset
            self.arcs = {}

        def addarc(self, next, label):
            self.arcs[label] = next

        def unifystate(self, old, new):
            for label, state in self.arcs.items():
                if state == old:
                    self.arcs[label] = new

        def __

# Generated at 2024-06-01 15:58:55.935292
```python
    pg = ParserGenerator()
    pg.dfas = {
        'A': [DFAState({NFAState(): 1}, NFAState())],
        'B': [DFAState({NFAState(): 1}, NFAState())]
    }
    pg.first = {}
    pg.calcfirst = lambda name: pg.first.update({name: {name.lower(): 1}})
    
    pg.addfirstsets()
    
    assert 'A' in pg.first
    assert 'B' in pg.first
    assert pg.first['A'] == {'a': 1}
    assert pg.first['B'] == {'b': 1}
```

# Generated at 2024-06-01 15:59:00.060342
```python
    # Mocking necessary components
    class MockToken:
        NAME = 1
        STRING = 2
        OP = 3

    class MockNFAState:
        def __init__(self):
            self.arcs = []

        def addarc(self, state, label=None):
            self.arcs.append((label, state))

    class MockParserGenerator:
        def __init__(self):
            self.value = None
            self.type = None
            self.generator = iter([])

        def gettoken(self):
            pass

        def expect(self, type, value=None):
            return value

        def parse_rhs(self):
            return MockNFAState(), MockNFAState()

        def parse_atom(self):
            a = MockNFAState()
            z = MockNFAState()
            a.addarc(z, self.value)
            return a, z

        def parse_item(self):
            if self.value == "[":
                self.get

# Generated at 2024-06-01 15:59:03.751572
```python
    import tokenize
    from io import StringIO

    # Mock generator to simulate token stream
    def mock_generator():
        tokens = [
            (tokenize.NAME, 'test', (1, 0), (1, 4), 'test\n'),
            (tokenize.NEWLINE, '\n', (1, 4), (1, 5), 'test\n'),
            (tokenize.COMMENT, '# comment', (2, 0), (2, 9), '# comment\n'),
            (tokenize.NL, '\n', (2, 9), (2, 10), '# comment\n'),
            (tokenize.STRING, '"string"', (3, 0), (3, 8), '"string"\n'),
        ]
        for token in tokens:
            yield token

    class MockParserGenerator:
        def __init__(self):
            self.generator = mock_generator()
            self.type = None
           

# Generated at 2024-06-01 15:59:32.493029
```python
    pg = ParserGenerator()
    pg.generator = iter([
        (token.OP, '[', (1, 0), (1, 1), '[...'),
        (token.NAME, 'NAME', (1, 1), (1, 5), 'NAME'),
        (token.OP, ']', (1, 5), (1, 6), ']'),
        (token.ENDMARKER, '', (1, 6), (1, 7), '')
    ])
    pg.gettoken()

    a, z = pg.parse_item()
    assert isinstance(a, NFAState)
    assert isinstance(z, NFAState)
    assert len(a.arcs) == 1
    assert a.arcs[0][1] == z

    pg.generator = iter([
        (token.NAME, 'NAME', (1, 0), (1, 4), 'NAME'),
        (token.OP, '+', (1, 

# Generated at 2024-06-01 15:59:34.986605
```python
    pg = ParserGenerator()
    pg.filename = "testfile"
    pg.end = (1, 5)
    pg.line = "test line"
    try:
        pg.raise_error("test error %s", "message")
    except SyntaxError as e:
        assert str(e) == "test error message ('testfile', 1, 5, 'test line')"
    else:
        assert False, "SyntaxError not raised"
```

# Generated at 2024-06-01 15:59:37.879042
```python
    pg = ParserGenerator()
    pg.dfas = {
        'A': [DFAState({NFAState(): 1}, NFAState())],
        'B': [DFAState({NFAState(): 1}, NFAState())]
    }
    pg.first = {}
    
    # Test non-recursive case
    pg.dfas['A'][0].arcs = {'a': pg.dfas['B'][0]}
    pg.dfas['B'][0].arcs = {'b': pg.dfas['B'][0]}
    pg.calcfirst('A')
    assert pg.first['A'] == {'a': 1}
    assert pg.first['B'] == {'b': 1}
    
    # Test recursive case
    pg.dfas['A'][0].arcs = {'A': pg.dfas['A'][0]}
    try:
        pg.calcfirst('A')
    except ValueError as e

# Generated at 2024-06-01 15:59:39.807564
```python
    pg = ParserGenerator()
    pg.dfas = {
        'S': [DFAState({NFAState(): 1}, NFAState())],
        'A': [DFAState({NFAState(): 1}, NFAState())]
    }
    pg.first = {}
    pg.calcfirst = lambda name: pg.first.update({name: {}})
    pg.addfirstsets()
    assert 'S' in pg.first
    assert 'A' in pg.first
```

# Generated at 2024-06-01 15:59:42.655543
```python
    class MockDFAState:
        def __init__(self, arcs, isfinal=False):
            self.arcs = arcs
            self.isfinal = isfinal

    class MockParserGenerator(ParserGenerator):
        def __init__(self):
            self.dfas = {
                'A': [MockDFAState({'B': None, 'c': None})],
                'B': [MockDFAState({'d': None})],
                'C': [MockDFAState({'e': None})]
            }
            self.first = {}
            self.startsymbol = 'A'
            self.symbol2number = {'A': 1, 'B': 2, 'C': 3}
            self.symbol2label = {}
            self.labels = []
            self.tokens = {}
            self.keywords = {}

        def calcfirst(self, name):
            if name == 'A':
                self.first[name] = {'B': 1, 'c

# Generated at 2024-06-01 15:59:45.423578
```python
    # Mocking necessary components
    class MockToken:
        NAME = 1
        STRING = 2
        OP = 3

    class MockNFAState:
        def __init__(self):
            self.arcs = []

        def addarc(self, state, label=None):
            self.arcs.append((label, state))

    class MockParserGenerator:
        def __init__(self):
            self.value = None
            self.type = None
            self.generator = iter([])

        def gettoken(self):
            pass

        def expect(self, type, value=None):
            return value

        def parse_rhs(self):
            return MockNFAState(), MockNFAState()

        def parse_atom(self):
            a = MockNFAState()
            z = MockNFAState()
            a.addarc(z, self.value)
            return a, z

        def parse_item(self):
            if self.value == "[":
                self.get

# Generated at 2024-06-01 15:59:46.638032
```python
    grammar = generate_grammar()
    assert isinstance(grammar, PgenGrammar)
    assert grammar.dfas is not None
    assert grammar.labels is not None
    assert grammar.keywords is not None
    assert grammar.tokens is not None
```

# Generated at 2024-06-01 15:59:48.722772
```python
    c = PgenGrammar()
    c.symbol2number = {'test': 1}
    c.labels = []
    c.tokens = {}
    c.keywords = {}
    c.symbol2label = {}
    
    pg = ParserGenerator()
    pg.first = {'test': {'a': 1, 'b': 1}}
    
    result = pg.make_first(c, 'test')
    
    expected = {0: 1, 1: 1}
    
    assert result == expected, f"Expected {expected}, but got {result}"
```

# Generated at 2024-06-01 15:59:52.458240
```python
    # Mocking necessary components
    class MockToken:
        NAME = 1
        STRING = 2
        OP = 3

    class MockNFAState:
        def __init__(self):
            self.arcs = []

        def addarc(self, state, label=None):
            self.arcs.append((label, state))

    class MockParserGenerator:
        def __init__(self):
            self.value = None
            self.type = None
            self.generator = iter([])

        def gettoken(self):
            pass

        def expect(self, type, value=None):
            return value

        def parse_rhs(self):
            return MockNFAState(), MockNFAState()

        def parse_atom(self):
            a = MockNFAState()
            z = MockNFAState()
            a.addarc(z, self.value)
            return a, z

        def parse_item(self):
            if self.value == "[":
                self.get

# Generated at 2024-06-01 15:59:54.263966
```python
    pg = ParserGenerator()
    try:
        pg.raise_error("Test error message %s", "with argument")
    except SyntaxError as e:
        assert str(e) == "Test error message with argument"
        assert e.args[1] == (pg.filename, pg.end[0], pg.end[1], pg.line)
    else:
        assert False, "SyntaxError not raised"
```

# Generated at 2024-06-01 16:00:44.362336
```python
    from io import StringIO
    import tokenize

    grammar = """
    start: expr
    expr: term ('+' term)*
    term: factor ('*' factor)*
    factor: '(' expr ')' | NAME
    """
    
    class MockToken:
        def __init__(self, type, value):
            self.type = type
            self.value = value

    class MockGenerator:
        def __init__(self, tokens):
            self.tokens = tokens
            self.index = 0

        def __iter__(self):
            return self

        def __next__(self):
            if self.index >= len(self.tokens):
                raise StopIteration
            token = self.tokens[self.index]
            self.index += 1
            return token

    tokens = [
        (token.NAME, 'start', (1, 0), (1, 5), 'start: expr'),
        (token.OP, ':', (1, 

# Generated at 2024-06-01 16:00:46.259925
```python
    pg = ParserGenerator()
    try:
        pg.raise_error("Test error message: %s", "something went wrong")
    except SyntaxError as e:
        assert str(e) == "Test error message: something went wrong"
        assert e.args[1] == (pg.filename, pg.end[0], pg.end[1], pg.line)
    else:
        assert False, "SyntaxError not raised"
```

# Generated at 2024-06-01 16:00:50.013621
```python
    from io import StringIO
    import sys

    # Create a mock NFAState class
    class NFAState:
        def __init__(self):
            self.arcs = []

        def addarc(self, next, label=None):
            self.arcs.append((label, next))

    # Create a mock ParserGenerator class with the dump_nfa method
    class ParserGenerator:
        def dump_nfa(self, name, start, finish):
            print("Dump of NFA for", name)
            todo = [start]
            for i, state in enumerate(todo):
                print("  State", i, state is finish and "(final)" or "")
                for label, next in state.arcs:
                    if next in todo:
                        j = todo.index(next)
                    else:
                        j = len(todo)
                        todo.append(next)
                    if label is None:
                        print("    -> %d" % j)
                    else:
                        print("

# Generated at 2024-06-01 16:00:55.125068
```python
    pg = ParserGenerator()
    pg.dfas = {
        'A': [DFAState({NFAState(): 1}, NFAState())],
        'B': [DFAState({NFAState(): 1}, NFAState())]
    }
    pg.first = {}
    
    # Test case 1: Simple non-recursive rule
    pg.dfas['A'][0].arcs = {'a': pg.dfas['B'][0]}
    pg.calcfirst('A')
    assert pg.first['A'] == {'a': 1}
    
    # Test case 2: Rule with recursion
    pg.dfas['B'][0].arcs = {'b': pg.dfas['A'][0]}
    try:
        pg.calcfirst('B')
    except ValueError as e:
        assert str(e) == "recursion for rule 'B'"
    
    # Test case 3: Rule with multiple first

# Generated at 2024-06-01 16:00:58.867146
```python
    class MockDFAState:
        def __init__(self, isfinal, arcs):
            self.isfinal = isfinal
            self.arcs = arcs

    dfa = [
        MockDFAState(False, {'a': 1, 'b': 2}),
        MockDFAState(True, {'c': 0}),
        MockDFAState(False, {'d': 1})
    ]

    pg = ParserGenerator()
    pg.dump_dfa("test", dfa)
```

# Generated at 2024-06-01 16:01:02.071943
```python
    from io import StringIO
    import sys

    # Create a mock NFAState class
    class NFAState:
        def __init__(self):
            self.arcs = []

        def addarc(self, next, label=None):
            self.arcs.append((label, next))

    # Create a mock ParserGenerator class with the dump_nfa method
    class ParserGenerator:
        def dump_nfa(self, name, start, finish):
            print("Dump of NFA for", name)
            todo = [start]
            for i, state in enumerate(todo):
                print("  State", i, state is finish and "(final)" or "")
                for label, next in state.arcs:
                    if next in todo:
                        j = todo.index(next)
                    else:
                        j = len(todo)
                        todo.append(next)
                    if label is None:
                        print("    -> %d" % j)
                    else:
                        print("

# Generated at 2024-06-01 16:01:05.512052
```python
    class MockDFAState:
        def __init__(self, isfinal, arcs):
            self.isfinal = isfinal
            self.arcs = arcs

    dfa = [
        MockDFAState(False, {'a': 1, 'b': 2}),
        MockDFAState(True, {'c': 0}),
        MockDFAState(False, {'d': 1})
    ]

    pg = ParserGenerator()
    pg.dump_dfa("test", dfa)
```

# Generated at 2024-06-01 16:01:10.044706
```python
    # Create a mock DFAState class for testing
    class MockDFAState:
        def __init__(self, nfaset, isfinal=False):
            self.nfaset = nfaset
            self.isfinal = isfinal
            self.arcs = {}

        def addarc(self, next, label):
            self.arcs[label] = next

        def unifystate(self, old, new):
            for label, state in self.arcs.items():
                if state == old:
                    self.arcs[label] = new

        def __eq__(self, other):
            if not isinstance(other, MockDFAState):
                return False
            return self.nfaset == other.nfaset and self.arcs == other.arcs

    # Create a mock ParserGenerator class for testing
    class MockParserGenerator:
        def simplify_dfa(self, dfa):
            changes = True
            while changes:
                changes = False

# Generated at 2024-06-01 16:01:14.220921
```python
    from io import StringIO
    import sys

    # Create a mock NFAState class
    class NFAState:
        def __init__(self):
            self.arcs = []

        def addarc(self, next, label=None):
            self.arcs.append((label, next))

    # Create a mock ParserGenerator class with the dump_nfa method
    class ParserGenerator:
        def dump_nfa(self, name, start, finish):
            print("Dump of NFA for", name)
            todo = [start]
            for i, state in enumerate(todo):
                print("  State", i, state is finish and "(final)" or "")
                for label, next in state.arcs:
                    if next in todo:
                        j = todo.index(next)
                    else:
                        j = len(todo)
                        todo.append(next)
                    if label is None:
                        print("    -> %d" % j)
                    else:
                        print("

# Generated at 2024-06-01 16:01:17.817947
```python
    # Mocking necessary components
    class MockToken:
        NAME = 1
        STRING = 2
        OP = 3

    class MockNFAState:
        def __init__(self):
            self.arcs = []

        def addarc(self, state, label=None):
            self.arcs.append((label, state))

    class MockParserGenerator:
        def __init__(self):
            self.value = None
            self.type = None
            self.generator = iter([])

        def gettoken(self):
            pass

        def expect(self, type, value=None):
            return value

        def parse_item(self):
            a = MockNFAState()
            b = MockNFAState()
            a.addarc(b, self.value)
            return a, b

    # Test case 1: Single item
    pg = MockParserGenerator()
    pg.value = "test"
    pg.type = MockToken.NAME
    a

# Generated at 2024-06-01 16:02:55.761869
```python
    generator = iter([
        (token.NAME, 'test', (1, 0), (1, 4), 'test'),
        (token.OP, ':', (1, 5), (1, 6), ':'),
        (token.NEWLINE, '\n', (1, 6), (1, 7), '\n')
    ])
    pg = ParserGenerator(generator, 'testfile')
    
    # Test expecting a NAME token
    assert pg.expect(token.NAME) == 'test'
    
    # Test expecting an OP token with value ':'
    assert pg.expect(token.OP, ':') == ':'
    
    # Test expecting a NEWLINE token
    assert pg.expect(token.NEWLINE) == '\n'
    
    # Test raising an error when the expected token type does not match
    try:
        pg.expect(token.STRING)
    except SyntaxError as e:
        assert str(e) == "expected 3/None,

# Generated at 2024-06-01 16:02:58.741252
```python
    # Mocking necessary components
    class MockToken:
        NAME = 1
        STRING = 2
        OP = 3

    class MockNFAState:
        def __init__(self):
            self.arcs = []

        def addarc(self, state, label=None):
            self.arcs.append((label, state))

    class MockParserGenerator:
        def __init__(self, tokens):
            self.tokens = tokens
            self.index = 0
            self.value = tokens[0][1]
            self.type = tokens[0][0]

        def gettoken(self):
            self.index += 1
            if self.index < len(self.tokens):
                self.type, self.value = self.tokens[self.index]
            else:
                self.type, self.value = None, None

        def expect(self, type, value=None):
            if self.type != type or (value is not None and self.value != value):
                raise

# Generated at 2024-06-01 16:02:59.475228
```python
    g = PgenGrammar()
    assert isinstance(g, PgenGrammar)
```

# Generated at 2024-06-01 16:03:02.438812
```python
    pg = ParserGenerator()
    pg.dfas = {
        'A': [DFAState({NFAState(): 1}, NFAState())],
        'B': [DFAState({NFAState(): 1}, NFAState())]
    }
    pg.first = {}
    pg.calcfirst = lambda name: pg.first.update({name: {name: 1}})
    
    pg.addfirstsets()
    
    assert 'A' in pg.first
    assert 'B' in pg.first
    assert pg.first['A'] == {'A': 1}
    assert pg.first['B'] == {'B': 1}
```

# Generated at 2024-06-01 16:03:04.643587
```python
    generator = tokenize.generate_tokens(io.StringIO("a | b | c").readline)
    pg = ParserGenerator(generator, "testfile")
    pg.gettoken()  # Initialize the first token
    start, end = pg.parse_rhs()
    
    assert isinstance(start, NFAState)
    assert isinstance(end, NFAState)
    assert len(start.arcs) == 3  # Three alternatives: a, b, c
    assert all(isinstance(arc[1], NFAState) for arc in start.arcs)
    assert all(arc[1] is end for arc in end.arcs)
```

# Generated at 2024-06-01 16:03:07.722365
```python
    from io import StringIO
    import sys

    # Create a mock NFAState class
    class NFAState:
        def __init__(self):
            self.arcs = []

        def addarc(self, next, label=None):
            self.arcs.append((label, next))

    # Create a mock ParserGenerator class with the dump_nfa method
    class ParserGenerator:
        def dump_nfa(self, name, start, finish):
            print("Dump of NFA for", name)
            todo = [start]
            for i, state in enumerate(todo):
                print("  State", i, state is finish and "(final)" or "")
                for label, next in state.arcs:
                    if next in todo:
                        j = todo.index(next)
                    else:
                        j = len(todo)
                        todo.append(next)
                    if label is None:
                        print("    -> %d" % j)
                    else:
                        print("

# Generated at 2024-06-01 16:03:12.486230
```python
    import tokenize
    from io import StringIO

    class MockGenerator:
        def __init__(self, tokens):
            self.tokens = tokens
            self.index = 0

        def __next__(self):
            if self.index >= len(self.tokens):
                raise StopIteration
            token = self.tokens[self.index]
            self.index += 1
            return token

    class MockParserGenerator:
        def __init__(self, tokens):
            self.generator = MockGenerator(tokens)
            self.type = None
            self.value = None
            self.begin = None
            self.end = None
            self.line = None

        def gettoken(self):
            tup = next(self.generator)
            while tup[0] in (tokenize.COMMENT, tokenize.NL):
                tup = next(self.generator)
            self.type, self.value, self.begin, self.end, self.line = tup

    tokens = [
        (tokenize.COMMENT,

# Generated at 2024-06-01 16:03:15.569729
```python
    class MockPgenGrammar:
        def __init__(self):
            self.labels = []
            self.symbol2number = {}
            self.symbol2label = {}
            self.tokens = {}
            self.keywords = {}

    c = MockPgenGrammar()
    pg = ParserGenerator()

    # Test case 1: Non-terminal symbol
    c.symbol2number['expr'] = 1
    label = 'expr'
    result = pg.make_label(c, label)
    assert result == 0
    assert c.labels == [(1, None)]
    assert c.symbol2label['expr'] == 0

    # Test case 2: Named token
    import token
    label = 'NAME'
    result = pg.make_label(c, label)
    assert result == 1
    assert c.labels == [(1, None), (token.NAME, None)]
    assert c.tokens[token.NAME] == 1

    # Test case 3

# Generated at 2024-06-01 16:03:18.706475
```python
    generator = iter([
        (token.NAME, 'test', (1, 0), (1, 4), 'test'),
        (token.OP, ':', (1, 4), (1, 5), ':'),
        (token.NEWLINE, '\n', (1, 5), (1, 6), '\n')
    ])
    pg = ParserGenerator(generator, 'testfile')
    
    # Test expecting a NAME token
    assert pg.expect(token.NAME) == 'test'
    
    # Test expecting an OP token with value ':'
    assert pg.expect(token.OP, ':') == ':'
    
    # Test expecting a NEWLINE token
    assert pg.expect(token.NEWLINE) == '\n'
    
    # Test raising an error when the expected token type does not match
    try:
        pg.expect(token.NAME)
    except SyntaxError as e:
        assert str(e) == "expected 1/None,

# Generated at 2024-06-01 16:03:22.564764
```python
    pg = ParserGenerator()
    pg.generator = iter([
        (token.OP, '[', (1, 0), (1, 1), '[1]'),
        (token.NAME, 'a', (1, 1), (1, 2), '[1]'),
        (token.OP, ']', (1, 2), (1, 3), '[1]'),
        (token.ENDMARKER, '', (1, 3), (1, 4), '[1]')
    ])
    pg.gettoken()
    a, z = pg.parse_item()
    assert isinstance(a, NFAState)
    assert isinstance(z, NFAState)
    assert len(a.arcs) == 1
    assert a.arcs[0][1] == z

    pg.generator = iter([
        (token.NAME, 'a', (1, 0), (1, 1), 'a+'),
        (token.OP