# Automatically generated by Pynguin.
import typesystem.tokenize.tokenize_yaml as module_0

def test_case_0():
    try:
        str_0 = ', start_position='
        token_0 = module_0.tokenize_yaml(str_0)
    except BaseException:
        pass

def test_case_1():
    try:
        str_0 = ''
        token_0 = module_0.tokenize_yaml(str_0)
    except BaseException:
        pass

def test_case_2():
    try:
        bytes_0 = b'q\xf5\x81\xa4X\xa5\xecfU\x02H/\xfd\xd8\xe8\x0b\x0f\xb3'
        token_0 = module_0.tokenize_yaml(bytes_0)
    except BaseException:
        pass

def test_case_3():
    try:
        str_0 = '\n    Must match all of the sub-items.\n\n    You should instead consolidate into a single type, or use\n    schema inheritence instead of this.\n    '
        any_0 = module_0.validate_yaml(str_0, str_0)
    except BaseException:
        pass

def test_case_4():
    try:
        str_0 = '.0'
        token_0 = module_0.tokenize_yaml(str_0)
        bytes_0 = b'\xceL\xde\x1a\xcbK\x803\xc5g\x00_\x83\xbb\xb1\xd5\x88\x14'
        token_1 = module_0.tokenize_yaml(bytes_0)
    except BaseException:
        pass