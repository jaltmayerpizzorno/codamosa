# Automatically generated by Pynguin.
import typesystem.tokenize.tokenize_yaml as module_0

def test_case_0():
    pass

def test_case_1():
    str_0 = 'label'
    token_0 = module_0.tokenize_yaml(str_0)

def test_case_2():
    bytes_0 = b'1'
    token_0 = module_0.tokenize_yaml(bytes_0)

def test_case_3():
    str_0 = '{}'
    token_0 = module_0.tokenize_yaml(str_0)
    str_1 = '[]'
    token_1 = module_0.tokenize_yaml(str_1)
    str_2 = '\n    a: 1\n    b:\n      - 1\n      - 2\n      - 3\n    c: true\n    d: null\n    '
    token_2 = module_0.tokenize_yaml(str_2)

def test_case_4():
    str_0 = '\n        name: Joe Blogs\n        address:\n            street: 123 Normal Street\n            suburb: Normalville\n        hobbies:\n            - programming\n            - blogging\n            - sleep\n        active: true\n        '
    token_0 = module_0.tokenize_yaml(str_0)

def test_case_5():
    str_0 = '1'
    token_0 = module_0.tokenize_yaml(str_0)
    str_1 = '1.4'
    token_1 = module_0.tokenize_yaml(str_1)
    str_2 = 'true'
    token_2 = module_0.tokenize_yaml(str_2)
    str_3 = '"string"'
    token_3 = module_0.tokenize_yaml(str_3)
    str_4 = 'null'
    token_4 = module_0.tokenize_yaml(str_4)
    str_5 = '[1, "str", false, null, [1, 2, 3]]'
    token_5 = module_0.tokenize_yaml(str_5)
    var_0 = token_5.value
    var_1 = len(var_0)