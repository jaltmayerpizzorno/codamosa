# Automatically generated by Pynguin.
import typesystem.tokenize.tokenize_json as module_0

def test_case_0():
    bytes_0 = b'\xb09'
    token_0 = module_0.tokenize_json(bytes_0)

def test_case_1():
    str_0 = '\n      [\n        {\n          "name": "foo",\n          "age": 1\n        },\n        {\n          "name": "bar",\n          "age": 2\n        }\n      ]\n    '
    token_0 = module_0.tokenize_json(str_0)

def test_case_2():
    str_0 = '{"string": "foo", "int": 1, "float": 1.1}'
    token_0 = module_0.tokenize_json(str_0)

def test_case_3():
    str_0 = '{"a":[1,2,3], "c": {"b": 4}}'
    token_0 = module_0.tokenize_json(str_0)