# Automatically generated by Pynguin.
import blib2to3.pgen2.tokenize as module_0

def test_case_0():
    pass

def test_case_1():
    str_0 = '"abc" # comment\n"def"\n123'
    var_0 = iter(str_0)
    var_1 = var_0.__next__
    module_0.tokenize(var_1)

def test_case_2():
    int_0 = -1660
    tuple_0 = (int_0, int_0)
    untokenizer_0 = module_0.Untokenizer()
    untokenizer_0.add_whitespace(tuple_0)
    untokenizer_0.add_whitespace(tuple_0)

def test_case_3():
    int_0 = 256
    str_0 = 'Ifd\x0b81E'
    tuple_0 = (int_0, str_0)
    tuple_1 = ()
    untokenizer_0 = module_0.Untokenizer()
    untokenizer_0.compat(tuple_0, tuple_1)

def test_case_4():
    int_0 = -1670
    str_0 = 'M>@X9muUi/5'
    tuple_0 = (int_0, str_0)
    dict_0 = {str_0: tuple_0}
    untokenizer_0 = module_0.Untokenizer()
    untokenizer_0.compat(tuple_0, dict_0)

def test_case_5():
    str_0 = '*'
    var_0 = iter(str_0)
    var_1 = var_0.__next__
    module_0.tokenize(var_1)

def test_case_6():
    str_0 = 'KyqqJq\tp?4_~\n'
    var_0 = iter(str_0)
    var_1 = var_0.__next__
    module_0.tokenize(var_1)

def test_case_7():
    str_0 = '#%?\t<R/-GkmQO`'
    var_0 = iter(str_0)
    var_1 = var_0.__next__
    module_0.tokenize(var_1)

def test_case_8():
    untokenizer_0 = module_0.Untokenizer()
    int_0 = 1
    int_1 = 0
    int_2 = (int_0, int_1)
    untokenizer_0.add_whitespace(int_2)
    int_3 = (int_0, int_0)
    untokenizer_0.add_whitespace(int_3)
    int_4 = 2
    int_5 = (int_0, int_4)
    untokenizer_0.add_whitespace(int_5)
    int_6 = 3
    int_7 = (int_0, int_6)
    untokenizer_0.add_whitespace(int_7)
    int_8 = 4
    int_9 = (int_0, int_8)
    untokenizer_0.add_whitespace(int_9)
    int_10 = 5
    int_11 = (int_0, int_10)
    untokenizer_0.add_whitespace(int_11)