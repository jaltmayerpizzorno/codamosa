# Automatically generated by Pynguin.
import typesystem.tokenize.tokenize_json as module_0

def test_case_0():
    pass

def test_case_1():
    str_0 = 'false'
    token_0 = module_0.tokenize_json(str_0)

def test_case_2():
    str_0 = '{"key1":["value1"], "key2": "value2", "key3": {}}'
    token_0 = module_0.tokenize_json(str_0)

def test_case_3():
    str_0 = '{"a": 2}'
    token_0 = module_0.tokenize_json(str_0)
    str_1 = '{"a": 2, "b": 3}'
    token_1 = module_0.tokenize_json(str_1)
    str_2 = '{"a": {"b": 2}}'
    token_2 = module_0.tokenize_json(str_2)
    str_3 = '{"a": [1, 2, 3]}'
    token_3 = module_0.tokenize_json(str_3)
    str_4 = '{"a": ["c", "d", "e"]}'
    token_4 = module_0.tokenize_json(str_4)
    str_5 = '{"a": null}'
    token_5 = module_0.tokenize_json(str_5)
    str_6 = '{"a": true}'
    token_6 = module_0.tokenize_json(str_6)

def test_case_4():
    str_0 = '{"a": null}'
    token_0 = module_0.tokenize_json(str_0)