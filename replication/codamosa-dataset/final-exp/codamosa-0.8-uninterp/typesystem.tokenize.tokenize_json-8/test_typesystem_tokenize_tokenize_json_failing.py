# Automatically generated by Pynguin.
import typesystem.tokenize.tokenize_json as module_0
import typesystem.tokenize.tokens as module_1

def test_case_0():
    try:
        tokenizing_decoder_0 = module_0._TokenizingDecoder()
    except BaseException:
        pass

def test_case_1():
    try:
        bytes_0 = b'\xcd\xe6_\xc1\x9fDn\x97\x0b'
        token_0 = module_0.tokenize_json(bytes_0)
    except BaseException:
        pass

def test_case_2():
    try:
        str_0 = '\n    {\n        "foo": {\n            "bar": [\n               1,\n                2\n            ]\n        },\n        a": "b"\n    }\n    '
        token_0 = module_0.tokenize_json(str_0)
    except BaseException:
        pass

def test_case_3():
    try:
        bytes_0 = b''
        token_0 = module_0.tokenize_json(bytes_0)
    except BaseException:
        pass

def test_case_4():
    try:
        bytes_0 = b'&\xd4\x90#'
        bool_0 = False
        any_0 = module_0.validate_json(bytes_0, bool_0)
    except BaseException:
        pass

def test_case_5():
    try:
        str_0 = '{az{<2=X#Zqet_K'
        token_0 = module_0.tokenize_json(str_0)
    except BaseException:
        pass

def test_case_6():
    try:
        str_0 = 'type'
        token_0 = module_0.tokenize_json(str_0)
    except BaseException:
        pass

def test_case_7():
    try:
        str_0 = "n;8\t$C28?W'"
        token_0 = module_0.tokenize_json(str_0)
    except BaseException:
        pass

def test_case_8():
    try:
        bytes_0 = b'5\x8d1\xdf\xefE\x93\x90\xb4\xfa2'
        token_0 = module_0.tokenize_json(bytes_0)
        str_0 = '\n{\n    "name": "Dunder Mifflin Paper Company",\n    "employees": ["Michael Scott", "Jim Halpert", "Dwight Schrute"],\n    "headquarters": {\n        "city": "Scranton, PA",\n        "state": "Pennsylvania"\n    }\n}\n    '
        token_1 = module_0.tokenize_json(str_0)
        any_0 = module_0.validate_json(str_0, token_1)
    except BaseException:
        pass

def test_case_9():
    try:
        bytes_0 = b'fL9\xc2\x13"\xd7\x9b@\x86\xcd/'
        token_0 = module_0.tokenize_json(bytes_0)
    except BaseException:
        pass

def test_case_10():
    try:
        str_0 = '{}'
        token_0 = module_0.tokenize_json(str_0)
        str_1 = '{"foo": "bar"}'
        token_1 = module_0.tokenize_json(str_1)
        str_2 = 'bar'
        int_0 = 7
        int_1 = 11
        scalar_token_0 = module_1.ScalarToken(str_2, int_0, int_1, str_1)
        str_3 = ''
        token_2 = module_0.tokenize_json(str_3)
    except BaseException:
        pass

def test_case_11():
    try:
        str_0 = '{"foo": 1'
        token_0 = module_0.tokenize_json(str_0)
    except BaseException:
        pass

def test_case_12():
    try:
        str_0 = '\n    {\n        "foo":{\n            "bar": [\n   2           1,\n                2\n        &   ]\n        },\n        a": "b"\n    }\n    '
        token_0 = module_0.tokenize_json(str_0)
    except BaseException:
        pass

def test_case_13():
    try:
        str_0 = '\n    {\n        "foo": {\n            "bar": [\n   2           1,\n                2\n            ]\n        },\n        a": "b"\n    }\n    '
        token_0 = module_0.tokenize_json(str_0)
    except BaseException:
        pass

def test_case_14():
    try:
        str_0 = '\n    {\n       "foo" {\n            "bar": [\n               1,\n        c       2\n            ]\n       },\n      u a": "b"\n    }\n    '
        token_0 = module_0.tokenize_json(str_0)
    except BaseException:
        pass

def test_case_15():
    try:
        str_0 = '\n    {\n        "foo": {\n            "bar": [\n               1,\n                2\n            ]\n  )     },\n        a": "b"\n    }\n    '
        token_0 = module_0.tokenize_json(str_0)
    except BaseException:
        pass

def test_case_16():
    try:
        str_0 = '\n    {\n        "foo": {\n            "bar": [\n               1,\n                2\n            ]\n  )     },\n        a": "b"\n    }\n    '
        str_1 = 'true'
        token_0 = module_0.tokenize_json(str_1)
        token_1 = module_0.tokenize_json(str_0)
    except BaseException:
        pass

def test_case_17():
    try:
        str_0 = '\n    {\n        "foo": {\n           "bar": \n               1,\n                C\n           ]\n  )     },\n        a": "b"\n    }\n    '
        token_0 = module_0.tokenize_json(str_0)
    except BaseException:
        pass

def test_case_18():
    try:
        str_0 = '{"foo":'
        token_0 = module_0.tokenize_json(str_0)
    except BaseException:
        pass