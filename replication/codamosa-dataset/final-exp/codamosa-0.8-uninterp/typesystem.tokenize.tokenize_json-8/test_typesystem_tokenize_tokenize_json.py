# Automatically generated by Pynguin.
import typesystem.tokenize.tokenize_json as module_0
import typesystem.tokenize.tokens as module_1

def test_case_0():
    str_0 = '\n    {\n        "foo": {\n            "bar": [\n                1,\n                2\n            ]\n        },\n        "a": ""\n    }\n    '
    token_0 = module_0.tokenize_json(str_0)

def test_case_1():
    str_0 = 'false'
    token_0 = module_0.tokenize_json(str_0)

def test_case_2():
    str_0 = '{"name": "New York", "state" : "NY", "coordinates": [-74.0059, 40.7127]}'
    token_0 = module_0.tokenize_json(str_0)

def test_case_3():
    str_0 = '"foo"'
    token_0 = module_0.tokenize_json(str_0)
    str_1 = 'foo'
    int_0 = 0
    int_1 = 5
    scalar_token_0 = module_1.ScalarToken(str_1, int_0, int_1, str_0)
    str_2 = '123'
    token_1 = module_0.tokenize_json(str_2)
    int_2 = 123
    int_3 = 3
    scalar_token_1 = module_1.ScalarToken(int_2, int_0, int_3, str_2)
    str_3 = '123.456'
    token_2 = module_0.tokenize_json(str_3)
    float_0 = 123.456
    int_4 = 7
    scalar_token_2 = module_1.ScalarToken(float_0, int_0, int_4, str_3)
    token_3 = module_0.tokenize_json(str_3)
    bool_0 = True
    int_5 = 4
    scalar_token_3 = module_1.ScalarToken(bool_0, int_0, int_5, str_1)
    str_4 = 'null'
    token_4 = module_0.tokenize_json(str_4)
    bytes_0 = b'"foo"'
    token_5 = module_0.tokenize_json(str_2)
    token_6 = module_0.tokenize_json(bytes_0)
    scalar_token_4 = module_1.ScalarToken(str_1, int_0, int_1, str_0)