# Automatically generated by Pynguin.
import blib2to3.pgen2.tokenize as module_0
import blib2to3.pgen2.grammar as module_1

def test_case_0():
    try:
        str_0 = "$7[\x0baZ\\+=9g;;\tZ'"
        bytes_0 = b'^c\xc9$\xdf\xe1\xb5f\x02\xd4\x07\x98\x06'
        bytes_1 = b'\xa9H@\xa7o\xe1\x97\xb1\xe1\x81\xf3MQ\xb5#\xc1'
        var_0 = module_0.any()
        var_1 = module_0.group()
        list_0 = [var_1]
        stop_tokenizing_0 = module_0.StopTokenizing(*list_0)
        str_1 = 'SI'
        list_1 = [bytes_0, bytes_1]
        tuple_0 = (str_0, list_1)
        str_2 = 'O6NqbA'
        grammar_0 = module_1.Grammar()
        var_2 = module_0.printtoken(stop_tokenizing_0, str_1, tuple_0, str_2, grammar_0)
    except BaseException:
        pass

def test_case_1():
    try:
        grammar_0 = module_1.Grammar()
        module_0.tokenize(grammar_0)
    except BaseException:
        pass

def test_case_2():
    try:
        float_0 = -1508.0
        untokenizer_0 = module_0.Untokenizer()
        str_0 = untokenizer_0.untokenize(float_0)
    except BaseException:
        pass

def test_case_3():
    try:
        untokenizer_0 = module_0.Untokenizer()
        str_0 = '!3$0.%&!NL#\x0c\nq*KA l='
        str_1 = untokenizer_0.untokenize(str_0)
    except BaseException:
        pass

def test_case_4():
    try:
        int_0 = 54
        str_0 = 'C_56\t:[XS)U0XFr`'
        tuple_0 = (int_0, str_0)
        path_like_0 = None
        untokenizer_0 = module_0.Untokenizer()
        untokenizer_0.compat(tuple_0, path_like_0)
    except BaseException:
        pass

def test_case_5():
    try:
        bytes_0 = b'\x13\xa7\xfa\x1cR0\x9e\xc58\xd4\xfd\x03\xd7'
        tuple_0 = module_0.detect_encoding(bytes_0)
    except BaseException:
        pass

def test_case_6():
    try:
        iterable_0 = None
        str_0 = module_0.untokenize(iterable_0)
    except BaseException:
        pass

def test_case_7():
    try:
        token_error_0 = module_0.TokenError()
        int_0 = 52
        int_1 = 43
        tuple_0 = (int_0, int_1)
        untokenizer_0 = module_0.Untokenizer()
        untokenizer_0.add_whitespace(tuple_0)
    except BaseException:
        pass

def test_case_8():
    try:
        int_0 = -1797
        str_0 = ''
        token_error_0 = module_0.TokenError()
        tuple_0 = (int_0, str_0)
        int_1 = 3953
        untokenizer_0 = module_0.Untokenizer()
        untokenizer_0.compat(tuple_0, int_1)
    except BaseException:
        pass

def test_case_9():
    try:
        tuple_0 = None
        grammar_0 = module_1.Grammar()
        iterator_0 = module_0.generate_tokens(tuple_0, grammar_0)
        var_0 = grammar_0.copy()
        str_0 = module_0.untokenize(iterator_0)
    except BaseException:
        pass

def test_case_10():
    try:
        int_0 = -1665
        str_0 = '5Up"d*i1v~'
        tuple_0 = (int_0, str_0)
        list_0 = [tuple_0, str_0]
        list_1 = [str_0, list_0, tuple_0, int_0]
        untokenizer_0 = module_0.Untokenizer()
        untokenizer_0.compat(tuple_0, list_1)
    except BaseException:
        pass

def test_case_11():
    try:
        str_0 = None
        iterator_0 = module_0.generate_tokens(str_0)
        int_0 = -798
        tuple_0 = (int_0, int_0)
        untokenizer_0 = module_0.Untokenizer()
        untokenizer_0.add_whitespace(tuple_0)
        int_1 = 2
        tuple_1 = (int_1, str_0)
        set_0 = None
        untokenizer_0.compat(tuple_1, set_0)
    except BaseException:
        pass

def test_case_12():
    try:
        var_0 = module_0.any()
        str_0 = None
        iterator_0 = module_0.generate_tokens(str_0)
        int_0 = -798
        tuple_0 = (int_0, int_0)
        untokenizer_0 = module_0.Untokenizer()
        set_0 = {int_0, iterator_0, tuple_0}
        str_1 = untokenizer_0.untokenize(set_0)
    except BaseException:
        pass

def test_case_13():
    try:
        var_0 = module_0.group()
        tuple_0 = None
        str_0 = '=g1Eb'
        dict_0 = {str_0: tuple_0, str_0: var_0}
        untokenizer_0 = module_0.Untokenizer()
        str_1 = untokenizer_0.untokenize(dict_0)
    except BaseException:
        pass

def test_case_14():
    try:
        untokenizer_0 = module_0.Untokenizer()
        float_0 = None
        dict_0 = {float_0: untokenizer_0, untokenizer_0: float_0, float_0: float_0}
        var_0 = module_0.printtoken(untokenizer_0, float_0, dict_0, dict_0, untokenizer_0)
    except BaseException:
        pass

def test_case_15():
    try:
        var_0 = module_0.any()
        bytes_0 = b'\x01=\t,'
        int_0 = -798
        tuple_0 = (int_0, int_0)
        untokenizer_0 = module_0.Untokenizer()
        str_0 = ''
        tuple_1 = (int_0, str_0)
        dict_0 = {tuple_0: tuple_0, bytes_0: tuple_0, tuple_1: int_0, tuple_1: str_0}
        untokenizer_0.compat(tuple_1, dict_0)
    except BaseException:
        pass

def test_case_16():
    try:
        untokenizer_0 = module_0.Untokenizer()
        int_0 = 3
        str_0 = 'print'
        var_0 = (int_0, str_0)
        int_1 = 59
        str_1 = '('
        var_1 = (int_1, str_1)
        int_2 = 6
        str_2 = '1'
        var_2 = (int_2, str_2)
        str_3 = '+'
        var_3 = (int_2, str_3)
        var_4 = (int_2, str_2)
        str_4 = ')'
        var_5 = (int_1, str_4)
        var_6 = (int_1, str_4)
        var_7 = (int_0, str_0)
        str_5 = '3'
        var_8 = (int_2, str_5)
        var_9 = (int_2, str_3)
        var_10 = (int_2, str_5)
        var_11 = (int_1, str_4)
        var_12 = (int_1, str_4)
        var_13 = [var_0, var_1, var_2, var_3, var_4, var_5, var_6, var_7, var_3, var_8, var_9, var_10, var_11, var_12]
        str_6 = untokenizer_0.untokenize(var_13)
    except BaseException:
        pass